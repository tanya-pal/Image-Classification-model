{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VlhuHJ7WqWFb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEFSqNX0suHo"
      },
      "outputs": [],
      "source": [
        "data_train_path = 'location of train data'\n",
        "data_test_path = 'location of test data'\n",
        "data_val_path = 'location of validation data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pYNthfvsriKM"
      },
      "outputs": [],
      "source": [
        "#fix the image size\n",
        "img_width = 180\n",
        "img_height =180"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAsIbJFnrq2q"
      },
      "outputs": [],
      "source": [
        "#convert the image data in array format so that algo can be easly applied\n",
        "data_train = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_train_path,\n",
        "    shuffle=True,\n",
        "    image_size=(img_width, img_height),\n",
        "    batch_size=32,\n",
        "    validation_split=False) #we automatically divide the dataset in validation that's why we write it as false"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1H9BEvfscvW"
      },
      "outputs": [],
      "source": [
        "data_cat = data_train.class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGA6iMzrsZ52"
      },
      "outputs": [],
      "source": [
        "data_cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgDyysNHsdUn"
      },
      "outputs": [],
      "source": [
        "data_val = tf.keras.utils.image_dataset_from_directory(data_val_path,\n",
        "                                                       image_size=(img_height,img_width),\n",
        "                                                       batch_size=32,\n",
        "                                                        shuffle=False,\n",
        "                                                       validation_split=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCkP-J-osnd3"
      },
      "outputs": [],
      "source": [
        "data_test = tf.keras.utils.image_dataset_from_directory(\n",
        "data_test_path,\n",
        "    image_size=(img_height,img_width),\n",
        "    shuffle=False,\n",
        "    batch_size=32,\n",
        "    validation_split=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iX-fpO9Rsvlq"
      },
      "outputs": [],
      "source": [
        "#this is use to show every folder image in short format\n",
        "plt.figure(figsize=(10,10))\n",
        "for image, labels in data_train.take(1):\n",
        "    for i in range(9):\n",
        "        plt.subplot(3,3,i+1)\n",
        "        plt.imshow(image[i].numpy().astype('uint8'))\n",
        "        plt.title(data_cat[labels[i]])\n",
        "        plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt-kjzXjumzB"
      },
      "source": [
        "MODEL CREATION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VAAWSHNzuj1d"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7HsqOKSiuzfh"
      },
      "outputs": [],
      "source": [
        "#create layers for sequential model\n",
        "model = Sequential([\n",
        "    layers.Rescaling(1./255),\n",
        "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(32,3, padding='same',activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(128),\n",
        "    layers.Dense(len(data_cat))\n",
        "\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NHzu4Efu3NI"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLlrROaqv1wt"
      },
      "outputs": [],
      "source": [
        "epochs_size = 25\n",
        "history = model.fit(data_train, validation_data=data_val, epochs=epochs_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUStXArTyO9X"
      },
      "outputs": [],
      "source": [
        "#show the graph of accuracy and loss\n",
        "epochs_range = range(epochs_size)\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs_range,history.history['accuracy'],label = 'Training Accuracy')\n",
        "plt.plot(epochs_range, history.history['val_accuracy'],label = 'Validation Accuracy')\n",
        "plt.title('Accuracy')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs_range,history.history['loss'],label = 'Training Loss')\n",
        "plt.plot(epochs_range, history.history['val_loss'],label = 'Validation Loss')\n",
        "plt.title('Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeSe56teyUxs"
      },
      "outputs": [],
      "source": [
        "#convert the array into image\n",
        "image = 'corn.jpg'\n",
        "image = tf.keras.utils.load_img(image, target_size=(img_height,img_width))\n",
        "img_arr = tf.keras.utils.array_to_img(image)\n",
        "img_bat=tf.expand_dims(img_arr,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lWGh0TqyhXt"
      },
      "outputs": [],
      "source": [
        "predict = model.predict(img_bat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaVJ_qRpyw4G"
      },
      "outputs": [],
      "source": [
        "score = tf.nn.softmax(predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ULD4uW5y1VD"
      },
      "outputs": [],
      "source": [
        "print('Veg/Fruit in image is {} with accuracy of {:0.2f}'.format(data_cat[np.argmax(score)],np.max(score)*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttHr4HpMy22-"
      },
      "outputs": [],
      "source": [
        "model.save('Image_classify.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
